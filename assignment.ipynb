{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8110fc71",
   "metadata": {
    "problem_id": "ex1"
   },
   "source": [
    "#### Exercise 1\n",
    "<!-- @q -->\n",
    "\n",
    "1. What kinds of EDA techniques might you use to explore the following types of data:\n",
    "    - Numeric data?  \n",
    "    1 Operations like count, min, max, mean, standard deviation, median. Plot graphs like Histogram, Scatterplots.\n",
    "    2 Check for missing values.\n",
    "    3 Outlier Detection and Handling\n",
    "    4 Look at corelations between columns.\n",
    "    5 Data Transformation\n",
    "    6 Visualization\n",
    "    7 Feature Emgimeering\n",
    "\n",
    "    - Categorical data?  \n",
    "    1 Understand the data.\n",
    "    2 Handling missing and duplicate data and data transforming.\n",
    "    4 Single Variable Analysis or relation between multiple variables\n",
    "    5 Visualization and Summarization of result.\n",
    "\n",
    "    - The relationship between categorical and numeric data?\n",
    "    1 Categorical data and numerical data are connected. Categories can affect the numbers (like “male” or “female” categories affecting average height), and numbers can help describe what each category looks like (like the average age in each group)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b98cf",
   "metadata": {
    "part_id": "ex1-part1",
    "span": "ex1-part1.answer",
    "student": true
   },
   "source": [
    "*Enter your answer in this cell*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5af7624",
   "metadata": {
    "part_id": "ex1-part2"
   },
   "source": [
    "2. Generate some fake data (~1000 rows) with 1 categorical column (with 10 categories) and 2 numeric columns. Use the techniques you mentioned to explore the numeric, categorical, and the relationship between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b78018a6",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>year</th>\n",
       "      <th>gender</th>\n",
       "      <th>major</th>\n",
       "      <th>age</th>\n",
       "      <th>gpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>Male</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>19.3</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Female</td>\n",
       "      <td>Business</td>\n",
       "      <td>25.7</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Female</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>22.6</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Female</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>21.6</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>Female</td>\n",
       "      <td>Information Systems</td>\n",
       "      <td>18.1</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_id       year  gender                major   age   gpa\n",
       "0           1  Sophomore    Male           Psychology  19.3  3.38\n",
       "1           2   Graduate  Female             Business  25.7  2.74\n",
       "2           3     Senior  Female           Psychology  22.6  2.91\n",
       "3           4     Junior  Female          Engineering  21.6  2.79\n",
       "4           5   Freshman  Female  Information Systems  18.1  2.30"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set seed for repeatable results\n",
    "np.random.seed(42)\n",
    "\n",
    "# number of rows\n",
    "n = 1000\n",
    "\n",
    "# student ids\n",
    "student_id = np.arange(1, n + 1)\n",
    "\n",
    "# academic year categories\n",
    "years = np.random.choice(\n",
    "    ['Freshman', 'Sophomore', 'Junior', 'Senior', 'Graduate'],\n",
    "    size=n,\n",
    "    p=[0.2, 0.2, 0.2, 0.25, 0.15]  # rough distribution\n",
    ")\n",
    "\n",
    "# gender categories\n",
    "genders = np.random.choice(['Male', 'Female', 'Other'], size=n, p=[0.48, 0.48, 0.04])\n",
    "\n",
    "# majors\n",
    "majors = np.random.choice(\n",
    "    ['Computer Science', 'Information Systems', 'Business', 'Psychology', 'Biology', 'Engineering'],\n",
    "    size=n\n",
    ")\n",
    "\n",
    "# helper to sample ages by academic year\n",
    "def sample_age(year_array):\n",
    "    ages = []\n",
    "    for y in year_array:\n",
    "        if y == 'Freshman':\n",
    "            age = np.random.normal(18.5, 0.6)  # 18–19\n",
    "        elif y == 'Sophomore':\n",
    "            age = np.random.normal(19.5, 0.6)  # 19–20\n",
    "        elif y == 'Junior':\n",
    "            age = np.random.normal(20.5, 0.7)  # 20–21\n",
    "        elif y == 'Senior':\n",
    "            age = np.random.normal(21.8, 0.8)  # 21–23\n",
    "        else:  # Graduate\n",
    "            age = np.random.normal(25, 2.0)   # 22–30\n",
    "        ages.append(age)\n",
    "    return np.array(ages)\n",
    "\n",
    "# generate ages and GPA\n",
    "ages = sample_age(years)\n",
    "ages = np.clip(ages, 17, 30)  # keep realistic\n",
    "\n",
    "gpa = np.clip(np.random.normal(3.2, 0.4, size=n), 0.0, 4.0)  # between 0 and 4\n",
    "\n",
    "# add some missingness\n",
    "ages[np.random.rand(n) < 0.03] = np.nan\n",
    "gpa[np.random.rand(n) < 0.02] = np.nan\n",
    "\n",
    "# build dataframe\n",
    "df = pd.DataFrame({\n",
    "    'student_id': student_id,\n",
    "    'year': years,\n",
    "    'gender': genders,\n",
    "    'major': majors,\n",
    "    'age': np.round(ages, 1),\n",
    "    'gpa': np.round(gpa, 2)\n",
    "})\n",
    "\n",
    "# quick peek at data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9bdce91",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d32a8118",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89d6dab1",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df5799fe",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25320be1",
   "metadata": {
    "problem_id": "2"
   },
   "source": [
    "#### Exercise 2\n",
    "\n",
    "\n",
    "Generate a data set you can use with a supervised ML model.  The data should meet the following criteria:\n",
    "   - It should have 1000 rows\n",
    "   - It should have 6 columns, with one column (your \"target\" column being a boolean column), one categorical column with 5 categories, and 4 numeric columns.\n",
    "   - The numeric columns should have dramatically different scales - different means, different std. deviations.\n",
    "   - Each non-target column should have about 5% nulls.\n",
    "\n",
    "Make this data a little more interesting by calculating the target column using a noisy function of the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a941ebec",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "2-part1",
    "span": "2-part1.code",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 mean: 0.965\n",
      "each fold: [0.971 0.964 0.978 0.96  0.953]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# pick features and make a simple target\n",
    "X = df[['year', 'gender', 'major', 'age', 'gpa']].copy()   # features i want\n",
    "y = (df['gpa'] >= 3.0).astype(int)                         # 1 if gpa is 3 or more\n",
    "\n",
    "# fill missing numeric with median\n",
    "X[['age', 'gpa']] = X[['age', 'gpa']].fillna(X[['age', 'gpa']].median())\n",
    "\n",
    "# fill missing categorical with most frequent\n",
    "for col in ['year', 'gender', 'major']:\n",
    "    X[col] = X[col].fillna(X[col].mode().iloc[0])\n",
    "\n",
    "# turn categories into numbers\n",
    "X_enc = pd.get_dummies(X, drop_first=True)                 \n",
    "\n",
    "# make the model\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# 5 fold f1 score\n",
    "scores = cross_val_score(log_reg, X_enc, y, scoring='f1', cv=5)\n",
    "\n",
    "print(\"f1 mean:\", scores.mean().round(3))\n",
    "print(\"each fold:\", np.round(scores, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d660fce9",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "2-part1",
    "span": "2-part1.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53678de6",
   "metadata": {
    "problem_id": "ex2"
   },
   "source": [
    "#### Exercise 3\n",
    "\n",
    "Use whatever resources you need to figure out how to build an SKLearn ML pipelines. Use a pipeline to build an ML approach to predicting your target column in the preceding data with logistic regression.  I have set up the problem below so that you will write your code in a function function call that takes an SKLearn model and data frame and returns the results of a cross validation scoring routine.  \n",
    "\n",
    "I have not taught you how to do this; use the book, google, the notes, chatgpt, or whatever. This is a test of your ability to *find* information, and use this to construct a solution. Your solution should:\n",
    "\n",
    "- Use a transformer pipeline that processes your numeric and categorical features separately\n",
    "- Place everything in a pipeline with the classifier that is passed in to the function.\n",
    "- I've already implemented the call to cross_val_score - to make it work, you'll need to assign your pipeline to the `pipeline` variable.\n",
    "\n",
    "_Note: You could just feed this question to AI and get an answer, and chances are, it will be right. But if you do, you won't really learn much. So, be thoughtful in your use of AI here - you can use it to build the solution step by step, and it will explain how everything works. It's all in how you use it. So, it's your choice - go for the easy grade, or learn something._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd23a7",
   "metadata": {
    "part_id": "ex2-part1",
    "span": "ex2-part1.fill",
    "student": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m#You fill in the pipeline definition.  Make sure to:\u001b[39;00m\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# - process categorical features (using an imputer and one hot encoder)\u001b[39;00m\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# - process numeric features (using an imputer and StandardScaler)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# TODO: Replace with your code (fill)\u001b[39;00m\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# --- 5-fold CV using F1\u001b[39;00m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cross_val_score(pipeline, X, y, scoring=\u001b[33m\"\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m\"\u001b[39m, cv=\u001b[32m5\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m scores = \u001b[43mrun_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mF1 (5-fold): mean=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, std=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores.std()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFold scores:\u001b[39m\u001b[33m\"\u001b[39m, np.round(scores, \u001b[32m3\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mrun_classifier\u001b[39m\u001b[34m(df, classifier)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_classifier\u001b[39m(df,classifier):\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# Separate features/target\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     y = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtarget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mint\u001b[39m)  \u001b[38;5;66;03m# logistic expects numeric; 0/1 from boolean\u001b[39;00m\n\u001b[32m     15\u001b[39m     X = df.drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m#You fill in the pipeline definition.  Make sure to:\u001b[39;00m\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# - process categorical features (using an imputer and one hot encoder)\u001b[39;00m\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# - process numeric features (using an imputer and StandardScaler)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# TODO: Replace with your code (fill)\u001b[39;00m\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# --- 5-fold CV using F1\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'target'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# assume df already exists from exercise 2 with columns:\n",
    "# year, gender, major, age, gpa\n",
    "# if not, raise a friendly error\n",
    "required_cols = {'year', 'gender', 'major', 'age', 'gpa'}\n",
    "if not required_cols.issubset(set(df.columns)):\n",
    "    raise ValueError(\"df must have columns: year, gender, major, age, gpa\")\n",
    "\n",
    "# pick features and make a simple target\n",
    "X = df[['year', 'gender', 'major', 'age', 'gpa']].copy()   # features i want\n",
    "y = (df['gpa'] >= 3.0).astype(int)                         # target 1 if gpa at least 3\n",
    "\n",
    "# fill missing numeric with median\n",
    "X[['age', 'gpa']] = X[['age', 'gpa']].fillna(X[['age', 'gpa']].median())\n",
    "\n",
    "# fill missing categorical with most frequent\n",
    "for col in ['year', 'gender', 'major']:\n",
    "    X[col] = X[col].fillna(X[col].mode().iloc[0])\n",
    "\n",
    "# one hot encode all categories\n",
    "X_enc = pd.get_dummies(X, drop_first=True)                 \n",
    "\n",
    "# build random forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,    # enough trees for stable scores\n",
    "    random_state=42,     # repeatable\n",
    "    n_jobs=-1            # use all cores\n",
    ")\n",
    "\n",
    "# run 5 fold cv with f1\n",
    "scores = cross_val_score(rf, X_enc, y, scoring='f1', cv=5)\n",
    "\n",
    "print(\"rf f1 mean:\", scores.mean().round(3))\n",
    "print(\"rf each fold:\", np.round(scores, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06eb0b",
   "metadata": {
    "part_id": "ex2-part2"
   },
   "source": [
    "Try using a `RandomForestClassifier` in the preceding pipeline. Just call `run_classifier` with a `RandomForestClassifier`, and print out the results as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65de74c",
   "metadata": {
    "part_id": "ex2-part2",
    "span": "ex2-part2.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bbb3b1",
   "metadata": {
    "part_id": "ex2-part3"
   },
   "source": [
    "Normally, `RandomForestClassifier`s are considered to be more powerful than `LogisticRegression`.  Depending on your data, this may or may not be the case. Reflect on your answers - which one does better here, and why do you think that is?  Once again, you might use AI, but you should probably also try to _understand_ the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb72f7e",
   "metadata": {
    "part_id": "ex2-part3",
    "span": "ex2-part3.answer",
    "student": true
   },
   "source": [
    "*Enter your answer in this cell*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
